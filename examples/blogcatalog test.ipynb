{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import umap\n",
    "# Silence perf warning\n",
    "import warnings\n",
    "from numba.errors import NumbaPerformanceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=NumbaPerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import graph2vec\n",
    "import csrgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_blogcatalog(edgelist='./data/edges_blogcatalog.csv',\n",
    "                    labels='./data/group_edges_blogcatalog.csv'):\n",
    "    \"\"\"\n",
    "    Graph with cluster labels from blogcatalog\n",
    "    \"\"\"\n",
    "    G = nx.read_edgelist(edgelist, delimiter=',')\n",
    "    labels = pd.read_csv(labels, header=None)\n",
    "    labels.columns = ['node', 'label']\n",
    "    labels = labels.sort_values(by='node').reset_index(drop=True)\n",
    "    return G, labels\n",
    "\n",
    "def to_X(node_labels, embedder):\n",
    "    \"\"\"\n",
    "    Takes a series of node names and returns matrix of embeddings\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame.from_records(\n",
    "        node_labels.astype(str).apply(embedder.predict).values)\n",
    "    return X\n",
    "\n",
    "G, labels = make_blogcatalog()\n",
    "y = labels.label\n",
    "\n",
    "# pick up n_clusters automatically\n",
    "n_clusters = labels.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    labels.node, labels.label, test_size=0.10, \n",
    "    random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making walks... Done, T=3.71\n",
      "Mapping Walk Names... Done, T=4.43\n",
      "Training W2V... Done, T=83.14\n",
      "Fit Embedder: 92.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 277.58\n",
      "best CV score: 0.4971\n",
      "test score: 0.1654\n"
     ]
    }
   ],
   "source": [
    "for WALKLEN in [80]: # l in paper\n",
    " for EPOCH in [10]: # r in paper\n",
    "  for N_WEIGHT in [1.]:\n",
    "   for R_WEIGHT in [1.]:\n",
    "    for WINDOW in [10]: # k in paper\n",
    "     for EMBED_SIZE in [128]: # d in paper\n",
    "      for NS_EXP in [0.75]: # default, not in paper\n",
    "       for NEGATIVE in [5]: # default, not in paper\n",
    "        start_t = time.time()\n",
    "        embedder = graph2vec.Node2Vec(\n",
    "            walklen=WALKLEN,\n",
    "            epochs=EPOCH,\n",
    "            return_weight=R_WEIGHT,\n",
    "            neighbor_weight=N_WEIGHT,\n",
    "            w2vparams={'window': WINDOW,\n",
    "                       'size': EMBED_SIZE, \n",
    "                       'negative': NEGATIVE, \n",
    "                       'iter': 5,\n",
    "                       'ns_exponent': NS_EXP,\n",
    "                       'batch_words': 128}\n",
    "        )\n",
    "        embedder.fit(G)\n",
    "        print(f\"Fit Embedder: {time.time() - start_t:.2f}\")\n",
    "        logit = linear_model.LogisticRegressionCV(cv=10, scoring='f1_macro',\n",
    "                                                  max_iter=3000,\n",
    "                                                  solver='lbfgs',\n",
    "                                                  multi_class='ovr')\n",
    "        X_full = to_X(labels.node, embedder=embedder)\n",
    "        scaler = StandardScaler().fit(X_full)\n",
    "        logit.fit(scaler.transform(to_X(X_train, embedder=embedder)), y_train)\n",
    "        score = logit.scores_[1].mean(axis=0).max()\n",
    "        print(f\"Trained: {time.time() - start_t:.2f}\")\n",
    "        print(f'best CV score: {score :.4f}')\n",
    "        test_score = metrics.f1_score(\n",
    "            y_true=y_test,\n",
    "            y_pred=logit.predict(scaler.transform(to_X(X_test, embedder=embedder))),\n",
    "            average='macro'\n",
    "        )\n",
    "        print(f\"test score: {test_score :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/umap/sparse.py:247: NumbaPerformanceWarning: \u001b[1m\u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../../../anaconda3/lib/python3.7/site-packages/umap/utils.py\", line 409:\u001b[0m\n",
      "\u001b[1m@numba.njit(parallel=True)\n",
      "\u001b[1mdef build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../../../anaconda3/lib/python3.7/site-packages/umap/sparse.py\", line 176:\u001b[0m\n",
      "\u001b[1m    @numba.njit(parallel=True)\n",
      "\u001b[1m    def nn_descent(\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/umap/spectral.py:229: UserWarning: Embedding a total of 13 separate connected components using meta-embedding (experimental)\n",
      "  n_components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Embedder: 137.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 177.28\n",
      "best CV score: 0.4971\n",
      "test score: 0.0338\n",
      "Neighbors: 5, dist: 0.001, embed: 16\n",
      "------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../../../anaconda3/lib/python3.7/site-packages/umap/sparse.py\", line 176:\u001b[0m\n",
      "\u001b[1m    @numba.njit(parallel=True)\n",
      "\u001b[1m    def nn_descent(\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/umap/spectral.py:229: UserWarning: Embedding a total of 15 separate connected components using meta-embedding (experimental)\n",
      "  n_components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Embedder: 128.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mranger/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for N_NEIGHBORS in [5, 15]:\n",
    " for MIN_DIST in [0.001, 0.01]:\n",
    "  for EMBED_SIZE in [64, 128]:\n",
    "    start_t = time.time()\n",
    "    embedder = graph2vec.SKLearnEmbedder(\n",
    "        umap.UMAP,\n",
    "        n_neighbors=N_NEIGHBORS,\n",
    "        min_dist=MIN_DIST,\n",
    "        metric='euclidean',\n",
    "        n_components=EMBED_SIZE,\n",
    "    )\n",
    "    embedder.fit(G)\n",
    "    print(f\"Fit Embedder: {time.time() - start_t:.2f}\")\n",
    "    logit = linear_model.LogisticRegressionCV(cv=10, scoring='f1_macro',\n",
    "                                              max_iter=3000,\n",
    "                                              solver='lbfgs',\n",
    "                                              multi_class='ovr')\n",
    "    X_full = to_X(labels.node, embedder=embedder)\n",
    "    scaler = StandardScaler().fit(X_full)\n",
    "    logit.fit(scaler.transform(to_X(X_train, embedder=embedder)), y_train)\n",
    "    score = logit.scores_[1].mean(axis=0).max()\n",
    "    print(f\"Trained: {time.time() - start_t:.2f}\")\n",
    "    print(f'best CV score: {score :.4f}')\n",
    "    test_score = metrics.f1_score(\n",
    "        y_true=y_test,\n",
    "        y_pred=logit.predict(scaler.transform(to_X(X_test, embedder=embedder))),\n",
    "        average='macro'\n",
    "    )\n",
    "    print(f\"test score: {test_score :.4f}\")\n",
    "    print(f\"Neighbors: {N_NEIGHBORS}, dist: {MIN_DIST}, embed: {EMBED_SIZE}\"\n",
    "          \"\\n------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
