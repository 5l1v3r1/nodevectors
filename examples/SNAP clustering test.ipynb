{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn import cluster, metrics\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import graph2vec\n",
    "from graph2vec.graph import _sparse_normalize_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalClusteringOnLabels(clusters, groupLabels, verbose=True):\n",
    "    results = []\n",
    "    results.append(metrics.adjusted_mutual_info_score(clusters, groupLabels))\n",
    "    results.append(metrics.adjusted_rand_score(clusters, groupLabels))\n",
    "    results.append(metrics.fowlkes_mallows_score(clusters, groupLabels))\n",
    "    if verbose:\n",
    "        print(\"adj. MI score:   {0:.2f}\".format(results[0]))\n",
    "        print(\"adj. RAND score: {0:.2f}\".format(results[1]))\n",
    "        print(\"F-M score:       {0:.2f}\".format(results[2]))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data from http://snap.stanford.edu/data/email-Eu-core.html\n",
    "# Edge list\n",
    "res = requests.get('http://snap.stanford.edu/data/email-Eu-core.txt.gz', verify=False)\n",
    "edges = gzip.GzipFile(fileobj=io.BytesIO(res.content))\n",
    "edges = pd.read_csv(io.StringIO(edges.read().decode()), header=None, sep=' ')\n",
    "edges.columns = ['src', 'dest']\n",
    "# cluster labels per node\n",
    "res = requests.get('http://snap.stanford.edu/data/email-Eu-core-department-labels.txt.gz', verify=False)\n",
    "labels = gzip.GzipFile(fileobj=io.BytesIO(res.content))\n",
    "labels = pd.read_csv(io.StringIO(labels.read().decode()), header=None, sep=' ')\n",
    "labels.columns = ['node', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(t.src, t.dest) for t in edges.itertuples()])\n",
    "\n",
    "# Graph nodes should be ordered ints\n",
    "if not (np.array(list(G.nodes)) == np.arange(len(list(G.nodes)))).all():\n",
    "    raise ValueError(\"graph nodes are not ordered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making walks... Done, T=0.10\n",
      "Mapping Walk Names... Done, T=0.59\n",
      "Training W2V... Done, T=12.17\n",
      "retrieving embeddings\n",
      "Clustering\n",
      "adj. MI score:   0.65\n",
      "adj. RAND score: 0.54\n",
      "F-M score:       0.56\n"
     ]
    }
   ],
   "source": [
    "embed_size = 32\n",
    "n_clusters = labels.cluster.nunique()\n",
    "\n",
    "n2v = graph2vec.Node2Vec(\n",
    "    walklen=10,\n",
    "    epochs=100,\n",
    "    return_weight=1.0,\n",
    "    neighbor_weight=1.0,\n",
    "    threads=8,\n",
    "    w2vparams={'window': 4,\n",
    "               'size': embed_size, \n",
    "               'negative': 3, \n",
    "               'iter': 10,\n",
    "               'ns_exponent': 0.5,\n",
    "               'batch_words': 128}\n",
    ")\n",
    "n2v.fit(G, verbose=True)\n",
    "\n",
    "print(\"retrieving embeddings\")\n",
    "nodes = list(G.nodes)\n",
    "embeds = np.empty((len(nodes), embed_size))\n",
    "for i in nodes:\n",
    "    embeds[i] = n2v.predict(i)\n",
    "\n",
    "print(\"Clustering\")\n",
    "# Density based methods don't seem to perform well\n",
    "# Since we know ahead of time the nb of clusters\n",
    "# Agglomerative is best performing and has stable results\n",
    "agglo = cluster.AgglomerativeClustering(\n",
    "    n_clusters=n_clusters, \n",
    "    affinity='cosine', # euclidean with Ward is slightly worse\n",
    "    linkage='average'\n",
    ").fit(embeds).labels_\n",
    "\n",
    "x = evalClusteringOnLabels(agglo, labels.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP Score:\n",
      "adj. MI score:   0.65\n",
      "adj. RAND score: 0.56\n",
      "F-M score:       0.58\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "ump = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.01,\n",
    "    metric='euclidean',\n",
    "    n_components=embed_size,\n",
    ")\n",
    "umpembed = ump.fit_transform(\n",
    "    _sparse_normalize_rows(nx.adjacency_matrix(G))\n",
    ")\n",
    "umpagglo = cluster.AgglomerativeClustering(\n",
    "    n_clusters=n_clusters, \n",
    "    affinity='cosine', \n",
    "    linkage='average'\n",
    ").fit(umpembed).labels_\n",
    "\n",
    "print(\"UMAP Score:\")\n",
    "x = evalClusteringOnLabels(umpagglo, labels.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Score:\n",
      "adj. MI score:   0.52\n",
      "adj. RAND score: 0.41\n",
      "F-M score:       0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pcae = decomposition.PCA(\n",
    "    n_components=embed_size,\n",
    "    whiten=True\n",
    ")\n",
    "pcae = pcae.fit_transform(\n",
    "    _sparse_normalize_rows(nx.adjacency_matrix(G)).todense()\n",
    ")\n",
    "pcae = cluster.AgglomerativeClustering(\n",
    "    n_clusters=n_clusters, \n",
    "    affinity='cosine', \n",
    "    linkage='average'\n",
    ").fit(pcae).labels_\n",
    "\n",
    "print(\"PCA Score:\")\n",
    "x = evalClusteringOnLabels(pcae, labels.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Score:\n",
      "adj. MI score:   0.53\n",
      "adj. RAND score: 0.40\n",
      "F-M score:       0.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "pcae = manifold.SpectralEmbedding(\n",
    "    n_components=embed_size,\n",
    "    affinity='nearest_neighbors',\n",
    ")\n",
    "pcae = pcae.fit_transform(\n",
    "    _sparse_normalize_rows(nx.adjacency_matrix(G)).todense()\n",
    ")\n",
    "pcae = cluster.AgglomerativeClustering(\n",
    "    n_clusters=n_clusters, \n",
    "    affinity='cosine', \n",
    "    linkage='average'\n",
    ").fit(pcae).labels_\n",
    "\n",
    "print(\"Spectral Score:\")\n",
    "x = evalClusteringOnLabels(pcae, labels.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isomap Score:\n",
      "adj. MI score:   0.62\n",
      "adj. RAND score: 0.53\n",
      "F-M score:       0.55\n"
     ]
    }
   ],
   "source": [
    "pcae = manifold.Isomap(\n",
    "    n_components=embed_size,\n",
    "    n_neighbors=10,\n",
    ")\n",
    "pcae = pcae.fit_transform(\n",
    "    _sparse_normalize_rows(nx.adjacency_matrix(G)).todense()\n",
    ")\n",
    "pcae = cluster.AgglomerativeClustering(\n",
    "    n_clusters=n_clusters, \n",
    "    affinity='cosine', \n",
    "    linkage='average'\n",
    ").fit(pcae).labels_\n",
    "\n",
    "print(\"Isomap Score:\")\n",
    "x = evalClusteringOnLabels(pcae, labels.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isomap Score:\n",
      "adj. MI score:   0.59\n",
      "adj. RAND score: 0.52\n",
      "F-M score:       0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.58612166, 0.51612726, 0.53898639])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcae = manifold.LocallyLinearEmbedding(\n",
    "    n_components=embed_size,\n",
    "    n_neighbors=13,\n",
    ")\n",
    "pcae = pcae.fit_transform(\n",
    "    _sparse_normalize_rows(nx.adjacency_matrix(G)).todense()\n",
    ")\n",
    "pcae = cluster.AgglomerativeClustering(\n",
    "    n_clusters=n_clusters, \n",
    "    affinity='cosine', \n",
    "    linkage='average'\n",
    ").fit(pcae).labels_\n",
    "\n",
    "print(\"Isomap Score:\")\n",
    "evalClusteringOnLabels(pcae, labels.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
